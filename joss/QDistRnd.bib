@book{Nielsen-book,
  address =       {Cambridge, MA},
  author =        {M. A. Nielsen and I. L. Chuang},
  publisher =     {Cambridge Unive. Press},
  title =         {Quantum Computation and Quantum Infomation},
  year =          {2000},
}

@inproceedings{Tillich-Zemor-2009,
  author =        {Tillich, J.-P. and Z{\'e}mor, G.},
  booktitle =     {Proc. IEEE Int. Symp. Inf. Theory (ISIT)},
  month =         {June},
  pages =         {799-803},
  title =         {Quantum {LDPC} codes with positive rate and minimum
                   distance proportional to {$\sqrt{n}$}},
  year =          {2009},
  annote =        {},
  doi =           {10.1109/ISIT.2009.5205648},
}

@article{Zeng-Pryadko-2018,
  author =        {Zeng, Weilei and Pryadko, Leonid P.},
  journal =       {Phys. Rev. Lett.},
  month =         {Jun},
  pages =         {230501},
  publisher =     {American Physical Society},
  title =         {Higher-Dimensional Quantum Hypergraph-Product Codes
                   with Finite Rates},
  volume =        {122},
  year =          {2019},
  doi =           {10.1103/PhysRevLett.122.230501},
  url =           {https://link.aps.org/doi/10.1103/PhysRevLett.122.230501},
}

@article{Zeng-Pryadko-hprod-2020,
  author =        {Zeng, Weilei and Pryadko, Leonid P.},
  journal =       {Phys. Rev. A},
  pages =         {062402},
  title =         {Minimal distances for certain quantum product codes
                   and tensor products of chain complexes},
  volume =        {102},
  year =          {2020},
  annote =        {We use a map to quantum error-correcting codes and a
                   subspace projection to get lower bounds for minimal
                   homological distances in a tensor product of two
                   chain complexes of vector spaces over a finite field.
                   Homology groups of such a complex are described by
                   the K�nneth theorem. We give an explicit expression
                   for the distances when one of the complexes is a
                   linear map between two spaces. The codes in the
                   construction, subsystem product codes and their
                   gauge-fixed variants, generalize several known
                   families of quantum error-correcting codes.},
  doi =           {10.1103/PhysRevA.102.062402},
  url =           {https://link.aps.org/doi/10.1103/PhysRevA.102.062402},
}

@article{Kovalev-Pryadko-Hyperbicycle-2013,
  author =        {Kovalev, A. A. and Pryadko, L. P.},
  journal =       {Phys. Rev. A},
  month =         {July},
  pages =         {012311},
  title =         {Quantum {K}ronecker sum-product low-density
                   parity-check codes with finite rate},
  volume =        {88},
  year =          {2013},
  annote =        {We introduce an ansatz for quantum codes which gives
                   the hypergraph-product (generalized toric) codes by
                   Tillich and Z�mor and generalized bicycle codes by
                   MacKay et al. as limiting cases. The construction
                   allows for both the lower and the upper bounds on the
                   minimum distance; they scale as a square root of the
                   block length. Many thus defined codes have a finite
                   rate and limited-weight stabilizer generators, an
                   analog of classical low-density parity-check (LDPC)
                   codes. Compared to the hypergraph-product codes,
                   hyperbicycle codes generally have a wider range of
                   parameters; in particular, they can have a higher
                   rate while preserving the estimated error threshold.},
  doi =           {10.1103/PhysRevA.88.012311},
  url =           {https://doi.org/10.1103/PhysRevA.88.012311},
}

@InProceedings{Bravyi-Hastings-2013,
  author =	 {Sergey Bravyi and Matthew B. Hastings},
  title =	 {Homological Product Codes},
  booktitle =	 {Proc. of the 46th {ACM} Symposium on Theory of
                  Computing ({STOC} 2014)},
  year =	 2014,
  pages =	 {273-282},
  url =		 {https://arxiv.org/abs/1311.0885},
  eprint =	 {arXiv:1311.0885},
  annote =	 {Quantum codes with low-weight stabilizers known as
                  LDPC codes have been actively studied recently due
                  to their simple syndrome readout circuits and
                  potential applications in fault-tolerant quantum
                  computing. However, all families of quantum LDPC
                  codes known to this date suffer from a poor distance
                  scaling limited by the square-root of the code
                  length. This is in a sharp contrast with the
                  classical case where good families of LDPC codes are
                  known that combine constant encoding rate and linear
                  distance. Here we propose the first family of good
                  quantum codes with low-weight stabilizers. The new
                  codes have a constant encoding rate, linear
                  distance, and stabilizers acting on at most
                  $\sqrt{n}$ qubits, where $n$ is the code length. For
                  comparison, all previously known families of good
                  quantum codes have stabilizers of linear weight. Our
                  proof combines two techniques: randomized
                  constructions of good quantum codes and the
                  homological product operation from algebraic
                  topology. We conjecture that similar methods can
                  produce good stabilizer codes with stabilizer weight
                  $n^a$ for any $a>0$. Finally, we apply the
                  homological product to construct new small codes
                  with low-weight stabilizers.}
}

@article{Guth-Lubotzky-2014,
  author =        {Guth, L. and Lubotzky, A.},
  journal =       {Journal of Mathematical Physics},
  number =        {8},
  pages =         {082202},
  title =         {Quantum error correcting codes and 4-dimensional
                   arithmetic hyperbolic manifolds},
  volume =        {55},
  year =          {2014},
  annote =        {Using 4-dimensional arithmetic hyperbolic manifolds,
                   we construct some new homological quantum error
                   correcting codes. They are low density parity check
                   codes with linear rate and distance n Îµ. Their
                   rate is evaluated via Euler characteristic arguments
                   and their distance using Z2Z2 -systolic geometry.
                   This construction answers a question of Zemor [``On
                   Cayley graphs, surface codes, and the limits of
                   homological coding for quantum error correction,'' in
                   Proceedings of Second International Workshop on
                   Coding and Cryptology (IWCC), (Lecture Notes in
                   Computer Science). Vol. 5557 (2009), pp. 259-273],
                   who asked whether homological codes with such
                   parameters could exist at all.},
  doi =           {10.1063/1.4891487},
  url =           {https://doi.org/10.1063/1.4891487},
}

  @article{Panteleev-Kalachev-2019,
  author =	 {Pavel Panteleev and Gleb Kalachev},
  title =	 {Degenerate Quantum {LDPC} Codes With Good Finite
                  Length Performance},
  eprint =	 {1904.02703},
  year =	 2021,
  journal =	 {Quantum},
  volume =	 5,
  pages =	 585,
  doi =		 {10.22331/q-2021-11-22-585},
  annote =	 {We study the performance of small and medium length
                  quantum LDPC (QLDPC) codes in the depolarizing
                  channel. Only degenerate codes with the maximal
                  stabilizer weight much smaller than their minimum
                  distance are considered. It is shown that with the
                  help of an OSD-like post-processing the performance
                  of the standard belief propagation (BP) decoder on
                  many QLDPC codes can be improved by several orders
                  of magnitude. Using this new BP-OSD decoder we study
                  the performance of several known classes of
                  degenerate QLDPC codes including the hypergraph
                  product codes, the hyperbicycle codes, the
                  homological product codes, and the Haah's cubic
                  codes. We also construct several interesting
                  examples of short generalized bicycle codes. Some of
                  them have an additional property that their
                  syndromes are protected by small BCH codes, which
                  may be useful for the fault-tolerant syndrome
                  measurement. We also propose a new large family of
                  QLDPC codes that contains the class of hypergraph
                  product codes, where one of the used parity-check
                  matrices is square. It is shown that in some cases
                  such codes have better performance than the
                  hypergraph product codes. Finally, we demonstrate
                  that the performance of the proposed BP-OSD decoder
                  for some of the constructed codes is better than for
                  a relatively large surface code decoded by a
                  near-optimal decoder. }
}


@article{Evseev-1983,
  author =        {G. S. Evseev},
  journal =       {Probl. Peredachi Informacii},
  note =          {(In Russian)},
  pages =         {3-8},
  title =         {Complexity of decoding for linear codes.},
  volume =        {19},
  year =          {1983},
  annote =        {https://www.ams.org/mathscinet-getitem?mr=734143 The
                   author introduces the notion of $Q$ decoding of
                   linear codes. To each code is associated a $Q$
                   ensemble which is the product space of the Euclidean
                   space of dimension $n$ with the set of all
                   information ensembles of code $A$. Associated to the
                   $Q$ ensemble is a decoding algorithm. If the $Q$
                   ensemble of the linear code $A$ contains the coset
                   leaders of $A$ then $Q$ decoding is the same as
                   maximum likelihood decoding. Error probability of $Q$
                   decoding is upper bounded by 2 times the error
                   probability of maximum likelihood decoding. In part 4
                   the author proves the following theorem on the
                   complexity of $Q$ decoding: ``There exists a $Q$
                   decoding in a DSC such that for almost all linear
                   codes of length $n$ and rate $R$ the following holds:
                   $C_Q\le 2^{n\cdot(R(1-R)+O(1))},\;P_\varepsilon\le
                   2\cdot P_{\varepsilon_0}$.'' The proofs in the
                   English translation of the paper are too short to be
                   fully understood.},
  url =           {http://mi.mathnet.ru/ppi1159},
}

@article{Iyer-Poulin-2013,
  author =        {Pavithran Iyer and David Poulin},
  journal =       {{IEEE} Transactions on Information Theory},
  number =        {9},
  pages =         {5209-5223},
  title =         {Hardness of Decoding Quantum Stabilizer Codes},
  volume =        {61},
  year =          {2015},
  abstract =      {In this paper, we address the computational hardness
                   of optimally decoding a quantum stabilizer code. Much
                   like classical linear codes, errors are detected by
                   measuring certain check operators which yield an
                   error syndrome, and the decoding problem consists of
                   determining the most likely recovery given the
                   syndrome. The corresponding classical problem is
                   known to be NP-complete, and are appropriate a
                   similar decoding problem for quantum codes is also
                   known to be NP-complete. However, this decoding
                   strategy is not optimal in the quantum setting as it
                   does not consider error degeneracy, which causes
                   distinct errors to have the same effect on the code.
                   Here, we show that optimal decoding of stabilizer
                   codes (previously known to be NP-hard) is in fact
                   computationally much harder than optimal decoding of
                   classical linear codes, it is #P-complete.},
  doi =           {10.1109/TIT.2015.2422294},
  issn =          {1557-9654},
}

@article{magma-system,
  author =        {Bosma, Wieb and Cannon, John and Playoust, Catherine},
  journal =       {J. Symbolic Comput.},
  note =          {Computational algebra and number theory (London,
                   1993)},
  number =        {3-4},
  pages =         {235--265},
  title =         {The {M}agma algebra system. {I}. {T}he user language},
  volume =        {24},
  year =          {1997},
  annote =        {recommended citation for Magma},
  doi =           {10.1006/jsco.1996.0125},
  issn =          {0747-7171},
  url =           {https://doi.org/10.1006/jsco.1996.0125},
}

@article{Kovalev-Pryadko-FT-2013,
  author =        {Kovalev, A. A. and Pryadko, L. P.},
  journal =       {Phys. Rev. A},
  month =         {Feb},
  pages =         {020304(R)},
  publisher =     {American Physical Society},
  title =         {Fault tolerance of quantum low-density parity check
                   codes with sublinear distance scaling},
  volume =        {87},
  year =          {2013},
  annote =        {We discuss error-correction properties for families
                   of quantum low-density parity check (LDPC) codes with
                   relative distance that tends to zero in the limit of
                   large blocklength. In particular, we show that any
                   family of LDPC codes, quantum or classical, where
                   distance scales as a positive power of the block
                   length, $d \propto n^\alpha$, $\alpha>0$, can correct
                   all errors with certainty if the error rate per
                   (qu)bit is sufficiently small. We specifically
                   analyze the case of LDPC version of the quantum
                   hypergraph-product codes recently suggested by
                   Tillich and Z\'emor. These codes are a finite-rate
                   generalization of the toric codes, and, for
                   sufficiently large quantum computers, offer an
                   advantage over the toric codes.},
  doi =           {10.1103/PhysRevA.87.020304},
  url =           {https://doi.org/10.1103/PhysRevA.87.020304},
}

@phdthesis{Breuckmann-thesis-2017,
  author =        {N. P. Breuckmann},
  school =        {RWTH Aachen University},
  title =         {Homological quantum codes beyond the toric code},
  year =          {2017},
  annote =        {Computer architectures which exploit quantum
                   mechanical effects can solve computing tasks that are
                   otherwise impossible to perform. A quantum computer
                   operates on a number of small quantum mechanical
                   systems, known as quantum bits, or qubits. Since
                   these systems are realized on the scale of atoms,
                   they are very prone to errors. Errors occur when the
                   environment interacts with the qubits, a process
                   called decoherence. It is widely accepted that it
                   will not be possible to shield qubits completely from
                   the outside world. If one were to perform a quantum
                   computation on the qubits directly, then after a
                   short period of time the information present in the
                   qubits would be lost. To counter decoherence the
                   state of a qubit can be encoded into multiple
                   physical ones. This is called a quantum error
                   correcting code. Performing quantum error correction
                   allows one to extend the life time of the encoded
                   qubit arbitrarily, assuming that the rate of errors
                   remains below a certain threshold value. The use of
                   quantum codes creates an overhead in resources, as
                   for every logical qubit many more physical qubits are
                   needed. The resource overhead for fault-tolerance is
                   problematic, since realizing qubits will be costly,
                   and in the early stages of building quantum computers
                   the number of physical qubits will be limited. The
                   currently favored coding architecture is the toric
                   code and its variant the surface code in which the
                   physical qubits are put on a square grid in which
                   interactions are only between nearest neighbors. In
                   this thesis we will explore quantum codes in which
                   qubits interact as if they were nearest neighbors in
                   more exotic spaces. In the first part we will
                   consider closed surfaces with constant negative
                   curvature. We show how such surfaces can be
                   constructed and enumerate all quantum codes derived
                   from them which have less than 10.000 physical
                   qubits. For codes that are extremal in a certain
                   sense we perform numerical simulations to determine
                   the value of their threshold. Furthermore, we give
                   evidence that these codes can be used for more
                   overhead efficient storage as compared to the surface
                   code by orders of magnitude. We also show how to read
                   and write the encoded qubits while keeping their
                   connectivity low. In the second part we consider
                   codes in which qubits are layed-out according to a
                   four- dimensional geometry. Such codes allow for much
                   simpler decoding schemes compared to codes which are
                   two-dimensional. In particular, measurements do not
                   necessarily have to be repeated to obtain reliable
                   information about the error and the classical
                   hardware performing the error correction is greatly
                   simplified. We perform numerical simulations to
                   analyze the performance of these codes using decoders
                   based on local updates. We also introduce a novel
                   decoder based on techniques from machine learning and
                   image recognition to decode four-dimensional codes.},
  doi =           {10.18154/RWTH-2018-01100},
}

@inproceedings{Hu-Fossorier-Eleftheriou-2004,
  author =        {Xiao-Yu Hu and Fossorier, M. P. C. and
                   Eleftheriou, E.},
  booktitle =     {Communications, 2004 IEEE International Conference
                   on},
  month =         {June},
  pages =         {767-771},
  title =         {On the computation of the minimum distance of
                   low-density parity-check codes},
  volume =        {2},
  year =          {2004},
  abstract =      {Low-density parity-check (LDPC) codes in their
                   broader-sense definition are linear codes whose
                   parity-check matrices have fewer 1s than 0s. Finding
                   their minimum distance is therefore in general an
                   NP-hard problem. We propose a randomized algorithm
                   called nearest nonzero codeword search (NNCS)
                   approach to tackle this problem for iteratively
                   decodable LDPC codes. The principle of the NNCS
                   approach is to search codewords locally around the
                   all-zero codeword perturbed by minimal noise,
                   anticipating that the resultant nearest nonzero
                   codewords will most likely contain the
                   minimum-Hamming- weight codeword whose Hamming weight
                   is equal to the minimum distance of the linear code.
                   This approach has its roots in Berrou et al.'s
                   error-impulse method and a form of Fossorier's list
                   decoding for LDPC codes.},
  doi =           {10.1109/ICC.2004.1312605},
}

@inproceedings{Declercq-Fossorier-2008,
  author =        {Declercq, D. and Fossorier, M.},
  booktitle =     {Information Theory, 2008. ISIT 2008. IEEE
                   International Symposium on},
  month =         {July},
  pages =         {1963-1967},
  title =         {Improved impulse method to evaluate the low weight
                   profile of sparse binary linear codes},
  year =          {2008},
  abstract =      {In this paper, the impulse method to determine the
                   low weight profile of sparse codes is improved based
                   on efficient probabilistic approaches for reliability
                   based decoding that are adapted to this problem. As a
                   result, compared with previous approaches, the same
                   low weight profile can be obtained with a significant
                   time reduction (for example from 30 hours to a few
                   minutes) or more complete low weight profiles can be
                   determined in the same amount of time.},
  doi =           {10.1109/ISIT.2008.4595332},
}

@article{Dumer-Kovalev-Pryadko-IEEE-2017,
  author =        {I. Dumer and A. A. Kovalev and L. P. Pryadko},
  journal =       {IEEE Trans. Inf. Th.},
  month =         {July},
  number =        {7},
  pages =         {4675-4686},
  title =         {Distance Verification for Classical and Quantum
                   {LDPC} Codes},
  volume =        {63},
  year =          {2017},
  abstract =      {The techniques of distance verification known for
                   general linear codes are first applied to the quantum
                   stabilizer codes. Then, these techniques are
                   considered for classical and quantum (stabilizer)
                   low-density-parity-check (LDPC) codes. New complexity
                   bounds for distance verification with provable
                   performance are derived using the average weight
                   spectra of the ensembles of LDPC codes. These bounds
                   are expressed in terms of the erasure-correcting
                   capacity of the corresponding ensemble. We also
                   present a new irreducible-cluster technique that can
                   be applied to any LDPC code and takes advantage of
                   parity-checks' sparsity for both the classical and
                   quantum LDPC codes. This technique reduces complexity
                   exponents of all existing deterministic techniques
                   designed for generic stabilizer codes with small
                   relative distances, which also include all known
                   families of the quantum stabilizer LDPC codes.},
  doi =           {10.1109/TIT.2017.2690381},
  issn =          {0018-9448},
}

@article{Leon-1988,
  author =        {Leon, J. S.},
  journal =       {IEEE Trans. Info. Theory},
  month =         {Sep},
  number =        {5},
  pages =         {1354 -1359},
  title =         {A probabilistic algorithm for computing minimum
                   weights of large error-correcting codes},
  volume =        {34},
  year =          {1988},
  abstract =      {An algorithm is developed that can be used to find,
                   with a very low probability of error (10-100 or less
                   in many cases), the minimum weights of codes far too
                   large to be treated by any known exact algorithm. The
                   probabilistic method is used to find minimum weights
                   of all extended quadratic residue codes of length 440
                   or less. The probabilistic algorithm is presented for
                   binary codes, but it can be generalized to codes over
                   GF(q) with q gt;2},
  doi =           {10.1109/18.21270},
  issn =          {0018-9448},
}

@article{Kruk-1989,
  author =        {E. A. Kruk},
  journal =       {Probl. Peredachi Inf.},
  note =          {(In Russian)},
  number =        {3},
  pages =         {103-107},
  title =         {Decoding Complexity Bound for Linear Block Codes},
  volume =        {25},
  year =          {1989},
  annote =        {A new complexity bound is derived for
                   maximum-likelihood decoding of linear block codes in
                   a memoryless q-ary symmetric channel. The bound is
                   the best among all known bounds in the entire range
                   of code rates.},
  url =           {http://mi.mathnet.ru/eng/ppi665},
}

@article{Coffey-Goodman-1990,
  author =        {Coffey, J. T. and Goodman, R. M.},
  journal =       {IEEE Trans. Info. Theory},
  month =         {Sep},
  number =        {5},
  pages =         {1031 -1037},
  title =         {The complexity of information set decoding},
  volume =        {36},
  year =          {1990},
  abstract =      {Information set decoding is an algorithm for decoding
                   any linear code. Expressions for the complexity of
                   the procedure that are logarithmically exact for
                   virtually all codes are presented. The expressions
                   cover the cases of complete minimum distance decoding
                   and bounded hard-decision decoding, as well as the
                   important case of bounded soft-decision decoding. It
                   is demonstrated that these results are vastly better
                   than those for the trivial algorithms of searching
                   through all codewords or through all syndromes, and
                   are significantly better than those for any other
                   general algorithm currently known. For codes over
                   large symbol fields, the procedure tends towards a
                   complexity that is subexponential in the symbol size},
  doi =           {10.1109/18.57202},
  issn =          {0018-9448},
}


@Article{Cuellar-etal-2020,
  author =	 {M. P. Cu{\'e}llar and G{\'o}mez-Torrecillas, J.  and
                  F. J. Lobillo and G. Navarro},
  title =	 {Genetic algorithms with permutation-based
                  representation for computing the distance of linear
                  codes},
  year =	 2021,
  journal =	 {Swarm and Evolutionary Computation},
  volume =	 60,
  pages =	 100797,
  eprint =	 {arXiv:2002.12330},
  doi =		 {10.1016/j.swevo.2020.100797},
  annote =	 {Finding the minimum distance of linear codes is an
                  NP-hard problem. Traditionally, this computation has
                  been addressed by means of the design of algorithms
                  that find, by a clever exhaustive search, a linear
                  combination of some generating matrix rows that
                  provides a codeword with minimum weight. Therefore,
                  as the dimension of the code or the size of the
                  underlying finite field increase, so it does
                  exponentially the run time. In this work, we prove
                  that, given a generating matrix, there exists a
                  column permutation which leads to a reduced row
                  echelon form containing a row whose weight is the
                  code distance. This result enables the use of
                  permutations as representation scheme, in contrast
                  to the usual discrete representation, which makes
                  the search of the optimum polynomial time dependent
                  from the base field. In particular, we have
                  implemented genetic and CHC algorithms using this
                  representation as a proof of concept. Experimental
                  results have been carried out employing codes over
                  fields with two and eight elements, which suggests
                  that evolutionary algorithms with our proposed
                  permutation encoding are competitive with regard to
                  existing methods in the literature. As a by-product,
                  we have found and amended some inaccuracies in the
                  MAGMA Computational Algebra System concerning the
                  stored distances of some linear codes.}
}

@misc{nist-mm-format,
  author = {{National Institute of Standards and Technology}},
  howpublished =  {online},
  note =          {Accessed on May 27, 2019},
  title =         {Matrix Market exchange formats},
  year =          {2013},
  url =           {https://math.nist.gov/MatrixMarket/formats.html},
}

@InProceedings{Hastings-Haah-ODonnell-2020,
  author =	 {Matthew B. Hastings and Jeongwan Haah and
                  {O'Donnell}, Ryan},
  title =	 {Fiber Bundle Codes: Breaking the
                  {$N^{1/2}\mathop{\rm polylog}(N)$} barrier for
                  quantum {LDPC} Codes},
  booktitle = {STOC 2021: Proceedings of the 53rd Annual {ACM
                  SIGACT} Symposium on Theory of Computing},
  year =	 2021,
  pages =	 {1276–1288},
  month =	 {June},
  doi =		 {10.1145/3406325.3451005},
  eprint =	 {2009.03921},
  isbn =	 9781450380539,
  publisher =	 {Association for Computing Machinery},
  address =	 {New York, NY, USA},
  annote =	 { We present a quantum LDPC code family that has
                  distance $O(N^{3/5}/polylog(N))$ and
                  $\Theta(N^{3/5})$ logical qubits. This is the first
                  quantum LDPC code construction which achieves
                  distance greater than $N^{1/2}polylog(N)$. The
                  construction is based on generalizing the
                  homological product of codes to a fiber bundle.}
}

@article{Panteleev-Kalachev-2020,
  author =	 {Panteleev, Pavel and Kalachev, Gleb},
  journal =	 {IEEE Transactions on Information Theory},
  title =	 {Quantum {LDPC} codes with almost linear minimum
                  distance},
  year =	 2022,
  volume =	 68,
  number =	 1,
  pages =	 {213-229},
  doi =		 {10.1109/TIT.2021.3119384},
  eprint =	 {arXiv:2012.04068},
  annote =	 {We give a construction of quantum LDPC codes of
                  dimension Θ(logN) and distance Θ(N/logN) as the code
                  length N→∞. Using a product of chain complexes this
                  construction also provides a family of quantum LDPC
                  codes of distance Ω(N1−α/2/logN) and dimension
                  Ω(NαlogN), where 0≤α<1. We also introduce and study
                  a new operation called lifted product, which
                  naturally generalizes the product operations for
                  quantum codes and chain complexes.},
}

@Unpublished{Panteleev-Kalachev-2021,
  author =	 {Pavel Panteleev and Gleb Kalachev},
  title =	 {Asymptotically Good Quantum and Locally Testable
                  Classical LDPC Codes},
  note =	 {Unpublished},
  url =		 {https://arxiv.org/abs/2111.03654},
  year =	 2021,
  annote =	 {We study classical and quantum LDPC codes of
                  constant rate obtained by the lifted product
                  construction over non-abelian groups. We show that
                  the obtained families of quantum LDPC codes are
                  asymptotically good, which proves the qLDPC
                  conjecture. Moreover, we show that the produced
                  classical LDPC codes are also asymptotically good
                  and locally testable with constant query and
                  soundness parameters, which proves a well-known
                  conjecture in the field of locally testable codes.}
}

@ARTICLE{Breuckmann-Eberhardt-2020,
  author =	 {Breuckmann, Nikolas P. and Eberhardt, Jens N.},
  journal =	 {IEEE Transactions on Information Theory},
  title =	 {Balanced Product Quantum Codes},
  year =	 {2021},
  volume =	 {67},
  number =	 {10},
  pages =	 {6653-6674},
  doi =		 {10.1109/TIT.2021.3097347},
  eprint =	 {arXiv:2012.09271},
  annote =	 {This work provides the first explicit and non-random
                  family of [[N,K,D]] LDPC quantum codes which encode
                  K∈Θ(N45) logical qubits with distance D∈Ω(N35). The
                  family is constructed by amalgamating classical
                  codes and Ramanujan graphs via an operation called
                  balanced product.  Recently, Hastings-Haah-O'Donnell
                  and Panteleev-Kalachev were the first to show that
                  there exist families of LDPC quantum codes which
                  break the polylog(N)N−−√ distance barrier. However,
                  their constructions are based on probabilistic
                  arguments which only guarantee the code parameters
                  with high probability whereas our bounds hold
                  unconditionally.  Further, balanced products allow
                  for non-abelian twisting of the check matrices,
                  leading to a construction of LDPC quantum codes that
                  can be shown to have K∈Θ(N) and that we conjecture
                  to have linear distance D∈Θ(N). }
}
